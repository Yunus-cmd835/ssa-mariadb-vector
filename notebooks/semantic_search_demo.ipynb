{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d347f10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hbenn\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../client\")  # Adjust if needed\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from mariadb_vector_client import MariaDBVectorClient\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25969efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"distiluse-base-multilingual-cased-v2\")\n",
    "client = MariaDBVectorClient()\n",
    "retriever = client.as_langchain_retriever(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dbe6a76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_model = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"gpt2\",              # Local, lightweight\n",
    "    pad_token_id=50256         # Required for GPT-2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec60b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def answer_query(query):\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    prompt = f\"\"\"[INST] You are a multilingual tech expert helping users choose the best AI-powered smartphone.\n",
    "\n",
    "Use the following context to answer the question clearly and helpfully.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "[/INST]\"\"\"\n",
    "\n",
    "    response = qa_model(\n",
    "        prompt,\n",
    "        max_new_tokens=512,\n",
    "        truncation=True,\n",
    "        do_sample=False,\n",
    "        return_full_text=False\n",
    "    )[0][\"generated_text\"]\n",
    "\n",
    "    answer = response.strip()\n",
    "    for phrase in [\"Answer:\", query.strip(), \"Question:\", prompt.strip()]:\n",
    "        answer = answer.replace(phrase, \"\").strip()\n",
    "\n",
    "    if not answer or len(answer) < 10:\n",
    "        answer = \"рооройрпНройро┐роХрпНроХро╡рпБроорпН, роЗроирпНрод роХрпЗро│рпНро╡ро┐роХрпНроХрпБ роЪро░ро┐ропро╛рой рокродро┐ро▓рпИ роЙро░рпБро╡ро╛роХрпНроХ роорпБроЯро┐ропро╡ро┐ро▓рпНро▓рпИ.\"\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71147af6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тЬЕ Answer: рооройрпНройро┐роХрпНроХро╡рпБроорпН, роЗроирпНрод роХрпЗро│рпНро╡ро┐роХрпНроХрпБ роЪро░ро┐ропро╛рой рокродро┐ро▓рпИ роЙро░рпБро╡ро╛роХрпНроХ роорпБроЯро┐ропро╡ро┐ро▓рпНро▓рпИ.\n"
     ]
    }
   ],
   "source": [
    "query = \"рооро┐роХ роЪро┐ро▒роирпНрод AI роХрпЗрооро░ро╛ роХрпКрогрпНроЯ роорпКрокрпИро▓рпН роОродрпБ?\"\n",
    "print(\"тЬЕ Answer:\", answer_query(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e793c10f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markdownify in c:\\users\\hbenn\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.9 in c:\\users\\hbenn\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdownify) (4.14.2)\n",
      "Requirement already satisfied: six<2,>=1.15 in c:\\users\\hbenn\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdownify) (1.17.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hbenn\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4<5,>=4.9->markdownify) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\hbenn\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4<5,>=4.9->markdownify) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install markdownify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5f47364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ЁЯУ▒ Best AI Camera Phones\n",
      "=======================\n",
      "\n",
      "* Samsung Galaxy S24 Ultra\n",
      "* Google Pixel 8 Pro\n",
      "* iPhone 15 Pro Max\n"
     ]
    }
   ],
   "source": [
    "from markdownify import markdownify as md\n",
    "\n",
    "html = \"\"\"\n",
    "<h1>ЁЯУ▒ Best AI Camera Phones</h1>\n",
    "<ul>\n",
    "  <li>Samsung Galaxy S24 Ultra</li>\n",
    "  <li>Google Pixel 8 Pro</li>\n",
    "  <li>iPhone 15 Pro Max</li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "\n",
    "markdown = md(html)\n",
    "print(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2f8f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_markdown(query, answer):\n",
    "    from markdownify import markdownify as md\n",
    "    md_text = f\"# тЭУ Query\\n{query}\\n\\n# тЬЕ Answer\\n{md(answer)}\"\n",
    "    with open(\"output.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(md_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12241ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_markdown(\"рооро┐роХ роЪро┐ро▒роирпНрод AI роХрпЗрооро░ро╛ роХрпКрогрпНроЯ роорпКрокрпИро▓рпН роОродрпБ?\", \"Samsung Galaxy S24 Ultra роОройрпНрокродрпБ рооро┐роХ роЪро┐ро▒роирпНрод AI роХрпЗрооро░ро╛ роХрпКрогрпНроЯ роорпКрокрпИро▓рпН роЖроХрпБроорпН.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "104f7ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# тЭУ Query\n",
      "рооро┐роХ роЪро┐ро▒роирпНрод AI роХрпЗрооро░ро╛ роХрпКрогрпНроЯ роорпКрокрпИро▓рпН роОродрпБ?\n",
      "\n",
      "# тЬЕ Answer\n",
      "Samsung Galaxy S24 Ultra роОройрпНрокродрпБ рооро┐роХ роЪро┐ро▒роирпНрод AI роХрпЗрооро░ро╛ роХрпКрогрпНроЯ роорпКрокрпИро▓рпН роЖроХрпБроорпН.\n"
     ]
    }
   ],
   "source": [
    "with open(\"output.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b7b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446c87d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7655f643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a55c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc58f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mariadb-env",
   "language": "python",
   "name": "mariadb-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
